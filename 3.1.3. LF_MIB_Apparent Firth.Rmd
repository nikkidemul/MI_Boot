---
title: "3.1.3. LF_MIB_Apparent Firth"
author: "N. de Mul"
date: "2023-11-09"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# LF-PERIPRED - Apparent Firth 

We repeat the process for Firth's logistic regression, but we use logistf() instead of glm(). This results in minor differences in calculating or scripting things, but essentially yields the same construct of output in order to compare results. 

NB: for Firth it is necessary that all variables are numeric. It cannot deal with factor variables. 
We adjusted that in 3.LF_MI_Boot start. 


```{r}
library(logistf)
set.seed(21212)
backwardimp <- function(impsets, formula){
  
  #store output
  models <- list()
  
  #loop over imputed datasets
  for (i in 1:length(impsets)){
    impset <<- impsets[[i]] #<<- is used because it seems that logistf cannot look into function environment so we had to save it in the general enviroment. NB: if you reuse this script, make sure you don't use impset in another function, because it is invisibly stored in general environment and R will look into that first.
    
    #create models using logistf
    full <- logistf(formula, data=impset)
    bwmodel <- backward(full, slstay=0.157, trace=F, printwork=F, data=impset) #specify AIC criterion, trace T will print everything, which can be usefull but it is faster to set to F. 
    bwmodelF <- flic(bwmodel)
    models[[i]] <- bwmodelF
  }
  return(models)
}

modelsF <- backwardimp(impsets=Final_impF, formula=outcome~age+
                         open+
                         T34+
                         dummy_Neotx1+
                         transhiatal+
                         fev1_compl+
                         dummy_Hblow+
                         comorb_dm+
                         gender+
                         eGFR+
                         dummy_ASA34+
                         dummy_Hbhigh+
                         comorb_cardiovasc+
                         comorb_hypertension+
                         smoking+
                         dummy_Neotx3+
                         bmi+
                         tiff_compl)

```



Majority vote and final model: 

```{r}

# put all models in a list and prep the data for further processing 
extractmodels <- function(modelimplist){
  
  #store output 
  listmodeldfs <- list()
  
  #create loop over models of imputed datasets 
  for (i in 1:length(modelimplist)){
    modeli <- modelimplist[[i]]
    modeldf <- data.frame(modeli$coefficients)
    
    #get standard errors from logistf output
    modeldf2 <- as.data.frame(sqrt(diag(modeli$var)))
    
    #transformations to get the correct column names 
    modeldf3 <- modeldf %>% rownames_to_column("variable")
    modeldf4 <- modeldf2 %>% rownames_to_column("variable")
    modeldf4 <- modeldf4 %>% rename(se = "sqrt(diag(modeli$var))")
    
    #merge everything together and create output 
    modeldf5 <- merge(modeldf3, modeldf4, by="variable", all.x=TRUE)
    listmodeldfs[[i]] <- modeldf5
  }
  return(listmodeldfs)
}


#get the modeldata (coefficients and standard errors) from the list with models 
modeldata <- extractmodels(modelsF)


#then count how many times each predictor was selected in the final model. When selected >50% of the time, it should be kept in the final model. 

#first create long dataframe: 
modeldatamerged <- bind_rows(modeldata)

#function for a majority vote: 
majorityvote <- function(bindedset, impN, freq){
  nimp <- impN
  prop <- freq 
  calculatefreq <- function(nimp, prop) { V <- nimp * prop 
  return(V) } 
  vote <- calculatefreq(nimp, prop)
  
  
  finalmodel <- data.frame()
  
  count <- bindedset %>% group_by(variable) %>% mutate(freq=n()) %>% ungroup() %>% filter(freq > vote) %>% select(-freq)
  finalmodel <- count %>% group_by(variable) %>% summarise(Meancoef = mean(modeli.coefficients))
  return(finalmodel)

}

#final model: 
finalmodelimp <- majorityvote(modeldatamerged, impN=10, freq=0.5) 


#make transformation of column names 
modeldatamerged2 <- as.data.frame(modeldatamerged %>% rename(coef = "modeli.coefficients"))



### Pool the standard errors of coefficients using Rubins Rules 

rubins_rules_var <- function(estimates, ses, n_imputed_sets){
  
  #within study variance
  within_var <- mean(ses^2)
  
  #between study variance
  theta_bar <- mean(estimates)
  
  between_var <- sum( (estimates - theta_bar)^2)/n_imputed_sets
  
  #total variance
  total_var <- within_var + between_var + between_var/n_imputed_sets 
  
  return(total_var)
}

# do some transformations to be able to merge the standard errors with the final model dataframe 
results <- modeldatamerged2 %>% group_by(variable) %>% summarise(rubins_rules_var(estimates=coef, ses=se, n_imputed_sets=10))
standarderrors <- results
standarderrors <- standarderrors %>% rename(ses = "rubins_rules_var(estimates = coef, ses = se, n_imputed_sets = 10)")

#merge with final model
finalmodelimp$OR <- exp(finalmodelimp$Meancoef)
finalmodelimp2 <- merge(finalmodelimp, standarderrors, by="variable", all.x=TRUE)

#calculate 95% CI 
finalmodel3F <- finalmodelimp2
finalmodel3F$lower <- finalmodel3F$Meancoef - 1.96*sqrt(finalmodel3F$ses)
finalmodel3F$upper <- finalmodel3F$Meancoef + 1.96*sqrt(finalmodel3F$ses)
finalmodel3F$lowerOR <- exp(finalmodel3F$lower)
finalmodel3F$upperOR <- exp(finalmodel3F$upper)

#change order of variables to be able to compare model output: 
finalmodel3F <- finalmodel3F %>% select(variable, Meancoef, ses, lower, upper, OR, lowerOR, upperOR)

saveRDS(finalmodel3F,file=paste0("FinalmodelFirthsim",".rds"))

finalmodel3F

```

Then we calculate apparent performance on the individual imputed datasets.
First calculate linear predictor and predicted values. 


```{r}

predcalc <- function(impsets, finalmodeldf){
  
  #store output
  predimps <- list()
    model_coefs <- with(finalmodeldf, setNames(Meancoef, variable))
  
    #create loop over imputed datasets, using the final model coefficients, multiplying them with the variable values 
  for(i in 1:length(impsets)){
    datasetimp <- impsets[[i]]
    
    #we need to set everything to numeric 
    impsetprep <- datasetimp %>% mutate_if(is.factor, as.numeric)
    
    #multiply all model coefficients with their respective variable value, not using the intercept variable (-1)
    impsetprep <- impsetprep %>% mutate(finalmodellp = model_coefs["(Intercept)"] + rowSums(across(all_of(names(model_coefs)[-1]),
                                         ~ get(cur_column()) * model_coefs[cur_column()]))) 
    
    #paste this value to the imputed dataset as predicted value 
    impsetpred <- datasetimp
    impsetpred$lp <- impsetprep$finalmodellp
    impsetpred$pred <- 1/(1+exp(-impsetpred$lp))
    predimps[[i]] <- impsetpred
  }
  return(predimps)
}

#get the predicted values by final model for each imputed dataset 
impsetspredF <- predcalc(Final_impF, finalmodelimp)
```


Because we want to calculate IPA, we need to calculate a null model Brier score. Therefore we also have to calculate null predicted values. 


```{r}

#make null models 
nullmodels <- function(impsets){
  
  #store output
  nullmodels <- list()
  
  #loop over imputed datasets
  for (i in 1:length(impsets)){
    set <- impsets[[i]]
    #create models
    null <- logistf(outcome~1, data=set)
    nullmodels[[i]] <- null
  }
  return(nullmodels)
}


nullmodelsF <- nullmodels(Final_impF) #for logistic regression models, the output should be conform the prevalence of the outcome. 

#extract nullmodels
nulldataF <- extractmodels(nullmodelsF)

#we use the same script as above, we don't need to do a majority vote because we only included an intercept, but we want to summarise the coefficients so we use the same function to do so. 

nulldatamergeF <- bind_rows(nulldataF)

nullmodelimpF <- majorityvote(nulldatamergeF, impN=10, freq=0.5)  

predcalcnull <- function(predimpsets, nullmodeldf){ #extra stuk functie om beide in 1 dataframe te krijgen 
  #input for the function: the imputationsets including the predicted values of the final model and the final nullmodel (pooled). 
  
  #store output: 
  totalpreds <- list()
  
  #specify coefficients 
    model_coefs <- with(nullmodeldf, setNames(Meancoef, variable))
  
    #loop over imputed datasets 
  for(i in 1:length(predimpsets)){
    
    #specify each dataset
    predset <- predimpsets[[i]]
    
    #calculate null model predicted values 
    impsetprep <- predset %>% mutate_if(is.factor, as.numeric)
    impsetprep <- impsetprep %>% mutate(finalmodellp = as.numeric(model_coefs["(Intercept)"]))
    
    #calculate null model predicted values 
    impsetpred <- predset
    impsetpred$lpnull <- impsetprep$finalmodellp
    impsetpred$prednull <- 1/(1+exp(-impsetpred$lpnull))
    totalpreds[[i]] <- impsetpred
  }
  return(totalpreds)
}

#get new datasets, including the predicted value of the final model and the predicted values of the nullmodel
completeF <- predcalcnull(impsetspredF, nullmodelimpF) 

```

Not all performance measures can be pooled easily. For AUC, we want to do a logit transformation and then pool, and convert back to plogis. 

```{r}
#logit function to be able to transform AUC and pool AUC 

logit <- function(x){log(x / (1-x))}

#estimate log c-statistic in every imp set for pooling 
compute_c_stat_log_imp <- function(obs_outcome, pred_outcome, method="delong", direction="<"){
  
  #estimate c_stat
  c_stat <- pROC::auc( response = obs_outcome,
                       predictor = pred_outcome,
                       direction = direction,
                       method = method)
  
  #estimate confidence intervals appropriately
  variance <- pROC::var(c_stat)
  logit_se <- sqrt(variance)/(c_stat*(1-c_stat))
  return(c (logitauc = logit(as.numeric(c_stat)),
            logit_se=logit_se))
}

library(rms)
library(pROC)

#function to get all desired performance measures. We choose AUC, IPA, Brier, OE ratio and calibration intercept and slope, but you can tweak it to your liking. 

impPerf <- function(impsetspred){
  
  #store output
  performancetablesimp <- list()
  
  #create a loop over the imputed datasets, that now contains predicted values (pred) of the final model and predicted values of the nullmodel (prednull). 
  for(i in 1:length(impsetspred)){
    
    #calculate auc en logit_auc --> save the logit. We make sure we store these as a variable calles performanceM for all calculations, so we can later merge these sets together. 
    totalpred <- impsetspred[[i]] 
    performanceimp <- compute_c_stat_log_imp(obs_outcome=totalpred$outcome, pred_outcome=totalpred$pred)
    c_statlogdf <- as.data.frame(performanceimp)
    c_statlogdf <- c_statlogdf %>% rownames_to_column("performanceM")
    
    #calculate other performance statistics using val.prob, storing them as performance M variable in a seperate dataframe 
    performanceimp <- val.prob(totalpred$pred, as.numeric(totalpred$outcome), pl=FALSE)
    performancedf <- data.frame(performanceimp)
    performancedf <- performancedf %>% rownames_to_column("performanceM")
    performancedf <- performancedf %>% filter(!is.na(performanceM))
    
    #calculate performance statistics for the null model to calculate IPA further on
    performancenull <- val.prob(totalpred$prednull, as.numeric(totalpred$outcome), pl=FALSE)
    performancenulldf <- as.data.frame(performancenull)
    performancenulldf <- performancenulldf %>% rownames_to_column("performanceM")
    performancenulldf <- performancenulldf %>% filter(!is.na(performanceM)) ####dit moest ik erbij doen omdat hij om een of andere reden NA's kreeg, omdat er 1 variabele in kolom performanceM NA werd, en die nam hij mee met de Brier. 
  
    #now calculate the performance measures that are not returned by val.prop by hand (IPA, OE). We also transformed IPA when we were not yet sure how to pool IPA. 
    add.data.IPA <- data.frame(performanceM = "IPA", performanceimp = 1-((performancedf$performanceimp[performancedf$performanceM=="Brier"])/(performancenulldf$performancenull[performancenulldf$performanceM=="Brier"])))
    add.data.IPA2 <- data.frame(performanceM = "logitIPA", performanceimp=logit(as.numeric(add.data.IPA$performanceimp)))
    add.data.OE <- data.frame(performanceM = "OE", performanceimp = (mean(totalpred$outcome))/(mean(totalpred$pred)))
    dfperformance2 <- bind_rows(performancedf, c_statlogdf, add.data.IPA, add.data.IPA2, add.data.OE) #wrap it all toghether                          
    dfperformance3 <- dfperformance2 %>% filter(performanceM=="logitauc"|performanceM=="logit_se"|performanceM=="IPA"|performanceM=="logitIPA"|performanceM=="Slope" | performanceM=="Intercept" | performanceM=="Brier" | performanceM=="OE")
    performancetablesimp[[i]] <- dfperformance3
    
  }
  return(performancetablesimp)
}


performanceimpF <- impPerf(completeF) 


#stack the sets, pool (take average) and transform back.
performancelongF <- bind_rows(performanceimpF)
performancesummaryF <- performancelongF %>% group_by(performanceM)
performancesummary2F <- performancesummaryF %>% summarise(Meanperformance = mean(performanceimp), .groups="drop")
performancesummary2F$nonlogmean <- plogis(performancesummary2F$Meanperformance)


#now we have a table both including the logit mean and the mean of the original values. The only performance measure that we wanted to pool as logit was AUC, therefore we create a new table where all performance measures are in their right format: 

finalperformanceF <- performancesummary2F %>% select(performanceM, Meanperformance)
finalperformanceF$Meanperformance[finalperformanceF$performanceM=="logitauc"] <- performancesummary2F$nonlogmean[performancesummary2F$performanceM=="logitauc"]

finalperformanceF <- finalperformanceF %>% filter(performanceM != "logitIPA")
finalperformanceF <- finalperformanceF %>% filter( performanceM != "logit_se")
finalperformanceF$performanceM <- ifelse(finalperformanceF$performanceM=="logitauc", "AUC", finalperformanceF$performanceM)

#save finalmodel performance: 




#Pooling the SE's of the AUC, logit, we have to use the performancelong file again. We save these standard errors to later calculate the confidence intervals surrounding the AUC for both apparent and bootstrap (corrected) performance. 

# Rubin's rules voor SE c-statistic---
rubins_rules_var_auc <- function( estimates,
                                  ses,
                                  n_imputed_sets){
  # within study variance
  within_var <- mean( ses^2)
  
  # between study variance
  between_var <- (1 + ( 1/ n_imputed_sets)) * var( estimates)
  
  # total variance
  total_var <- within_var + between_var
  
  return( total_var)
}

total_var_performance_impF <- rubins_rules_var_auc(estimates=performancelongF$performanceimp[performancelongF$performanceM=="logitauc"], ses=performancelongF$performanceimp[performancelongF$performanceM=="logit_se"], n_imputed_sets=10) #is opgeslagen als totale variantie. 

total_var_performance_impF #0.01045727 --> simulation: 0.01059245

#and for Intercept and slope? 



```


Calibrationplot: 


```{r}
# smoot calibration curve van final model op stacked imputed datasets
#Nu als volgt ine en stacked lijst gezet: 
outcomestacked <- lapply(impsetspredF, function(x) x%>%select(outcome))
predstacked <- lapply(impsetspredF, function(x) x%>%select(pred))

y_inputcheck <- t( rbind( unlist( outcomestacked)))  

# provide coordinates of the smooth calibration curve ----
draw_smooth_calibration <- function( obs_outcome, pred_outcome){
  # dit moet wss aangepast naar eigen data, moet alle geobserveerde obs en pred
  # waarden zijn uit stacked imputed set.
  y_input <- t( rbind( unlist( obs_outcome)))
  x_input <- t( rbind( unlist( pred_outcome)))
  
  y_coordinates <- loess( y_input ~ x_input)$fitted #-1 -1 was necessary for GLM but not Firth (already numeric). 
  
  # store all coordinates of smooth curve (ordered based on x)
  smooth_cal_slope_info <- list( x_coordinates = x_input[order( x_input)],
                                 y_coordinates = y_coordinates[order( x_input)])
  
  
  # output overall info calibration slope
  return( smooth_cal_slope_info)
}

smooth_info <- draw_smooth_calibration(obs_outcome=outcomestacked, pred_outcome=predstacked)


plot_smooth_calibration <- function( x_coordinates,
                                     y_coordinates){
  plot(x = 1,                 
       xlab = "Estimated probability", 
       ylab = "Observed risk",
       xlim = c(0, 1), 
       ylim = c(0, 1),
       main = "",
       type = "n")
  
  # add reference line
  abline( a = 0, b = 1, lty = 2)
  
  # add smooth calibration curve
  lines( x = x_coordinates,
         y = y_coordinates)
  
  # add histogram at bottom
  par(new = T)
  # from rms val.prob function
  lim <- c(0,1)
  bins <- seq(lim[1], lim[2], length=101)
  x <- x_coordinates[x_coordinates >= lim[1] & x_coordinates <= lim[2]]
  f <- table(cut(x, bins))
  j <- f > 0
  bins <- (bins[-101])[j]
  f <- f[j]
  f <- lim[1] + .15 * diff(lim) * f / max(f)
  segments(bins, 0, bins, f)
}

calibrationplot <- plot_smooth_calibration(x_coordinates=smooth_info$x_coordinates, y_coordinates=smooth_info$y_coordinates) 

```



Deze resultaten even opslaan: 
```{r}
# saveRDS(calibrationplot,file=paste0("calibrationplotFsim",".rds"))
saveRDS(finalperformanceF,file=paste0("finalperformanceFsim",".rds"))
# 
# total_var_performance_imp #0.01041778 # 0.01059245 ((simulation))
total_var_performance_impGLM
```


95% confidence intervals for AUC: 

Confidence interval AUC (corrected) 
```{r}
plogis(logit(0.64)-1.96*sqrt(0.01158976))
plogis(logit(0.64)+1.96*sqrt(0.01158976))
```

```{r}
finalmodelimp
```



```{r}

Myimp$lpGLM <- -2.08216925 + 0.04415418*Myimp$age + 0.43302223*as.numeric(Myimp$comorb_hypertension) + -0.00853947*Myimp$fev1_compl + -0.46331381*as.numeric(Myimp$comorb_dm) + -0.50703939*as.numeric(Myimp$transhiatal) + 0.65085502*as.numeric(Myimp$open) + 0.39126824*as.numeric(Myimp$dummy_Neotx3)

Myimp$pred <- 1/(1+exp(-Myimp$lpF))
summary(Myimp$pred)
```
```{r}
library(pROC)
myROC <- roc(Myimp$outcome ~ Myimp$lpF, levels=c(0,1))
plot(myROC, xlim=c(1,0)) 

?roc()

auc(myROC)
```






